{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pylab as pl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets, model_selection, tree, preprocessing, metrics, linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import randint as sp_randint\n",
    "warnings.filterwarnings('ignore')\n",
    "linkname = 'bank_cleaned.csv'\n",
    "dataset = pd.read_csv(linkname)\n",
    "dataset = dataset.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>response</th>\n",
       "      <th>response_binary</th>\n",
       "      <th>month_int</th>\n",
       "      <th>age_group</th>\n",
       "      <th>balance_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>average balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>2.52</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>low balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>low balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>231</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>low balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>447</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>low balance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  day  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no    5   \n",
       "1   44    technician   single  secondary      no       29     yes   no    5   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes    5   \n",
       "3   35    management  married   tertiary      no      231     yes   no    5   \n",
       "4   28    management   single   tertiary      no      447     yes  yes    5   \n",
       "\n",
       "  month  duration  campaign  pdays  previous poutcome response  \\\n",
       "0   may      4.35         1     -1         0  unknown       no   \n",
       "1   may      2.52         1     -1         0  unknown       no   \n",
       "2   may      1.27         1     -1         0  unknown       no   \n",
       "3   may      2.32         1     -1         0  unknown       no   \n",
       "4   may      3.62         1     -1         0  unknown       no   \n",
       "\n",
       "   response_binary  month_int  age_group    balance_group  \n",
       "0                0        5.0       50.0  average balance  \n",
       "1                0        5.0       40.0      low balance  \n",
       "2                0        5.0       30.0      low balance  \n",
       "3                0        5.0       30.0      low balance  \n",
       "4                0        5.0       20.0      low balance  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select variables relevant to customers\n",
    "\n",
    "The most relevant variables worth considering from this dataset are job, education, age, balance, default record, housing record, and loan record.  The rest of the columns are not worth analyzing or modeling because they are not related to the customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['marital'], axis=1, inplace=True)\n",
    "dataset1 = dataset.iloc[:, 0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform categorical data into dummy variables\n",
    "\n",
    "The five categorical variables (job, education, default, housing, and loan) are transformed into dummy variables.  These dummy variables are used because categorical variables are not ordinal (numeric).  These variables represent different types rather than levels, so dummy variables are introduced to distinguish the effect of different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pd.get_dummies(dataset1, columns=['job'])\n",
    "dataset2 = pd.get_dummies(dataset2, columns=['education'])\n",
    "dataset2['housing'] = dataset2['housing'].map({'yes': 1, 'no': 0})\n",
    "dataset2['default'] = dataset2['default'].map({'yes': 1, 'no': 0})\n",
    "dataset2['loan'] = dataset2['loan'].map({'yes': 1, 'no': 0})\n",
    "dataset_response = pd.DataFrame(dataset['response_binary'])\n",
    "dataset2 = pd.merge(dataset2, dataset_response, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "\n",
    "The first 20 columns, which have the customer statistics, are selected as the features while the last column, 'campaign outcome', is the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset2.values\n",
    "X = array[:, 0:-1]\n",
    "Y = array[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Classification Algorithms\n",
    "\n",
    "Four different classification algorithms (Logistical Regression, K-Neighbors Classifier, Ramdom Forest Classifier, and GaussianNB) are used on the dataset and the best scoring one will be used to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('NB', GaussianNB()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.884287 (0.006382)\n",
      "KNN: 0.872674 (0.005091)\n",
      "RF: 0.870505 (0.003420)\n",
      "NB: 0.824577 (0.007188)\n"
     ]
    }
   ],
   "source": [
    "result_c = []\n",
    "names_c = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits = 10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    result_c.append(cv_results)\n",
    "    names_c.append(name)\n",
    "    message = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Performance of Classification Algorithms')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(result_c)\n",
    "ax.set_xticklabels(names_c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ml_algo(algo, X_train, Y_train, X_test, cv):\n",
    "    model = algo.fit(X_train, Y_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    if (isinstance(algo, (LogisticRegression, KNeighborsClassifier, GaussianNB, RandomForestClassifier,))):\n",
    "        probs = model.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        probs = \"Not Available\"\n",
    "    acc = round(model.score(X_test, Y_test) * 100, 2)\n",
    "    train_pred = model_selection.cross_val_predict(algo, X_train, Y_train, X_test, cv=cv, n_jobs=-1)\n",
    "    acc_cv = round(metrics.accuracy_score(Y_train, train_pred) * 100, 2)\n",
    "    return train_pred, test_pred, acc, acc_cv, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(Y_test, preds):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, prob)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.title('Receiver Operating Characteristics')\n",
    "    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1], 'r--')\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [28588, 28588, 12253]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d22ab5d42e8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_pred_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pred_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_cv_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_ml_algo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pred_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-04e08ac7279d>\u001b[0m in \u001b[0;36mfit_ml_algo\u001b[1;34m(algo, X_train, Y_train, X_test, cv)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Not Available\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0macc_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m     \"\"\"\n\u001b[1;32m--> 748\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \"\"\"\n\u001b[0;32m    292\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    257\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [28588, 28588, 12253]"
     ]
    }
   ],
   "source": [
    "train_pred_log, test_pred_log, acc_log, acc_cv_log, probs_log = fit_ml_algo(LogisticRegression(n_jobs=-1), X_train, Y_train, X_test, 10)\n",
    "print(metrics.classification_report(Y_train, train_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression is the best performing model.\n",
    "\n",
    "The logistical regression model has the highest score (88.5%), suggesting a high level of strength of this model to classify the customer response given all of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LR model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score is the percentage of correct predictions out of all of the predictions made.  This algorithm is 89.09% accurate, suggesting this model is very strong to classify the customer response given all of the defined customer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_test, predictions))\n",
    "cm = confusion_matrix(Y_test, predictions)\n",
    "pl.matshow(cm)\n",
    "pl.title('Confusion matrix of the classifier')\n",
    "pl.colorbar()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The accuracy of an algorithm can be misleading, especially if the data very unbalanced, because the number of observations in the different classes vary largely.</b>\n",
    "\n",
    "The confustion matrix gives a breakdown of the prediction result and error types.  In the test set, the matrix proves the algorithm performed very well because most of the results (7278 true positives, 0 false positives) are the correct predictions.  However, there were 891 false negatives, which means the algorithm predicted the client would subscribed, but they did not subscribe.\n",
    "\n",
    "The main problem revealed here is that the dataset is extremely unbalanced, with nearly all of the clients not subscribing.  This means that the accuracy score is biased, and further evaluation is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful interpreting this report.  The precision score of 0 means that for all instances predicted as no subscription, meaning that 89% of the clients said no.  Recall is the ability of a classifier to find all of the positive values.  A Recall score of 0 in this instance means that all of the clients said no, which was 100% correct in this case.\n",
    "\n",
    "The report shows that the LR model has great predictive power to identify the customers who would not subscribe to the term deposit.  Since there are so few clients actually subscribing to the deal, there is a need for stratified sampling or rebalancing to deal with the structual weakness of the data.  We cannot conclude that the LR algorithm can accurately classify those who are likely to subscribe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression analysis is used to complement the classification results and help the bank better predict the campaign outcome based on the customer's stats.\n",
    "\n",
    "Since the duration of a phone call is positively correlated with the outcome, it can serve as another indicator on the possibility of a subscription.  We will use regression here to find out the length of a phone call, helping the bank predict the actual subscription rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4 = dataset2.drop(['response_binary'], axis=1)\n",
    "dataset4['duration'] = dataset['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset4.values\n",
    "X = array[:,0:20]\n",
    "y = array[:,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('LASSO', Lasso()))\n",
    "models.append(('RIDGE', Ridge()))\n",
    "models.append(('EN', ElasticNet()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('RF', DecisionTreeRegressor()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_e2 = []\n",
    "names_e2 = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits = 10, random_state=10)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    result_e2.append(cv_results)\n",
    "    names_e2.append(name)\n",
    "    message = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(result_e2)\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax.set_xticklabels(names_e2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression slightly outperforms other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()), ('LR', LinearRegression())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()), ('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledRIDGE', Pipeline([('Scaler', StandardScaler()), ('RIDGE', Ridge())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()), ('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()), ('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()), ('CART', DecisionTreeRegressor())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_e2_normalized = []\n",
    "names_e2_normalized = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10, random_state=10)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    result_e2_normalized.append(cv_results)\n",
    "    names_e2_normalized.append(name)\n",
    "    message = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(result_e2_normalized)\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax.set_xticklabels(names_e2_normalized)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After standardization, ridge regression is still the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "predicted_y = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('The mean squared error is: ', mean_squared_error(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of the duration is extremely varied from 0.1 to 81.97 minutes.  A MSE of 17.78 means that the ridge regression is a sound model in predicting the target variable and suggests that the bank can estimate the duration of a campaign calls of each client using the customer's profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
